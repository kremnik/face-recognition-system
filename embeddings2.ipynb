{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import math\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import facenet\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file\n",
    "\n",
    "def load_model(model, sess):\n",
    "    model_exp = os.path.expanduser(model)\n",
    "    print('Model directory: %s' % model_exp)\n",
    "    meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "\n",
    "    print('Metagraph file: %s' % meta_file)\n",
    "    print('Checkpoint file: %s' % ckpt_file)\n",
    "\n",
    "    saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file))\n",
    "    saver.restore(sess, os.path.join(model_exp, ckpt_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(paths, batch_size):\n",
    "    nrof_images = len(paths)\n",
    "    nrof_batches = int(math.ceil(1.0*nrof_images / batch_size))\n",
    "    emb_array = np.zeros((nrof_images, embedding_size))\n",
    "\n",
    "    for i in range(nrof_batches):    \n",
    "        start_index = i*batch_size\n",
    "        end_index = min((i+1)*batch_size, nrof_images)\n",
    "        paths_batch = paths[start_index:end_index]\n",
    "        images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "        feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n",
    "        emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)    \n",
    "        print(\"batch number:\", i)\n",
    "    print(\"Complete\")\n",
    "    \n",
    "    return emb_array\n",
    "\n",
    "def printDistance(emb_array, label_list, end=10):\n",
    "    threshold = 1.0\n",
    "    lng = len(emb_array[:end])\n",
    "    print('Distance matrix')\n",
    "    print('    ', end='')\n",
    "    for i in range(lng):\n",
    "        print('    %3d     ' % i, end='')\n",
    "    print('')\n",
    "    for i in range(lng):\n",
    "        print('%1d  ' % i, end='')\n",
    "        for j in range(lng):\n",
    "            dist = np.linalg.norm(emb_array[i,:] - emb_array[j,:])\n",
    "            print('  %1.4f' % dist, end='')\n",
    "            if (label_list[i] == label_list[j]) and (dist <= threshold):\n",
    "                print(\"(TP)\", end='')\n",
    "            elif (label_list[i] != label_list[j]) and (dist > threshold):\n",
    "                print(\"(TN)\", end='')\n",
    "            elif (label_list[i] == label_list[j]) and (dist > threshold):\n",
    "                print(\"\\033[93m(FN)\\033[0m\", end='')\n",
    "            elif (label_list[i] != label_list[j]) and (dist <= threshold):\n",
    "                print(\"\\033[93m(FP)\\033[0m\", end='')\n",
    "        print('')\n",
    "        \n",
    "def printData(labels, paths, number):\n",
    "    for i in range(number):\n",
    "        if i > 0 and labels[i] != labels[i-1]:\n",
    "            print('')\n",
    "        print('{0:3d} {1:3d}   {2:s}'.format(i, labels[i], paths[i].split(\"\\\\\")[1]))\n",
    "        # print('{0:3d}   {1:s}'.format(labels[i], paths[i].split(\"\\\\\")[1]))\n",
    "        \n",
    "def PCAtransform(emb_array, n_components = 10):\n",
    "    pca = PCA(n_components, whiten=True)\n",
    "    pca.fit(emb_array)\n",
    "    return pca.transform(emb_array), pca\n",
    "\n",
    "def splitTrainTest(data_set, percent_train):\n",
    "    paths, labels_list = facenet.get_image_paths_and_labels(data_set)\n",
    "    \n",
    "    lng = len(paths)\n",
    "    lng_train = int(lng * percent_train / 100);\n",
    "    lng_test = lng - lng_train\n",
    "    \n",
    "    train_paths = paths[0:lng_train]\n",
    "    test_paths = paths[lng_train:]\n",
    "    \n",
    "    train_labels = labels_list[0:lng_train]\n",
    "    test_labels = labels_list[lng_train:]\n",
    "    \n",
    "    return train_paths, train_labels, test_paths, test_labels\n",
    "\n",
    "def trainFisher(emb_array, y):\n",
    "    emb_del = np.empty_like(emb_array)\n",
    "    np.copyto(emb_del, emb_array)\n",
    "    \n",
    "    emb_array = np.vstack((emb_array, y))\n",
    "    \n",
    "    # y = emb_array[sample_number]\n",
    "    # emb_del = np.delete(emb_array, (sample_number), axis=0)\n",
    "    \n",
    "    E = np.linalg.inv(np.cov(emb_array.T))\n",
    "    D = (y - (1 / (len(emb_array) - 1) * np.sum(emb_del)))\n",
    "    \n",
    "    w = np.dot(E, D)\n",
    "    c = np.dot(w / np.linalg.norm(w), y)\n",
    "    \n",
    "    return c, w\n",
    "\n",
    "def trainFisherWithNum(emb_array, sample_number):    \n",
    "    y = emb_array[sample_number]\n",
    "    emb_del = np.delete(emb_array, (sample_number), axis=0)\n",
    "    \n",
    "    E = np.linalg.inv(np.cov(emb_array.T))\n",
    "    D = (y - (1 / (len(emb_array) - 1) * np.sum(emb_del)))\n",
    "    \n",
    "    w = np.dot(E, D)\n",
    "    c = np.dot(w / np.linalg.norm(w), y)\n",
    "    \n",
    "    return c, w    \n",
    "\n",
    "def Fisher(w, c, sample):\n",
    "    return np.dot(w / np.linalg.norm(w), sample) - c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = facenet.get_dataset(\"../../datasets/ownpeople/ownpeople_mtcnnpy_160/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_paths, train_labels, test_paths, test_labels = splitTrainTest(data_set, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: 20170511-185253\n",
      "Metagraph file: model-20170511-185253.meta\n",
      "Checkpoint file: model-20170511-185253.ckpt-80000\n",
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from 20170511-185253\\model-20170511-185253.ckpt-80000\n"
     ]
    }
   ],
   "source": [
    "load_model(\"20170511-185253\", sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "image_size = 160\n",
    "embedding_size = embeddings.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number: 0\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "emb_array = forward(train_paths, 100) # 100 means 100 mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix\n",
      "          0           1           2           3           4           5           6           7           8           9     \n",
      "0    0.0000(TP)  0.5827(TP)  0.5887(TP)  0.6242(TP)  0.6273(TP)  0.8732(TP)  0.6039(TP)  0.5684(TP)  0.8186(TP)  0.7623(TP)\n",
      "1    0.5827(TP)  0.0000(TP)  0.5602(TP)  0.6899(TP)  0.7414(TP)  0.8884(TP)  0.6791(TP)  0.6024(TP)  0.7650(TP)  0.6863(TP)\n",
      "2    0.5887(TP)  0.5602(TP)  0.0000(TP)  0.5301(TP)  0.7963(TP)  0.8490(TP)  0.7058(TP)  0.6925(TP)  0.7630(TP)  0.7677(TP)\n",
      "3    0.6242(TP)  0.6899(TP)  0.5301(TP)  0.0000(TP)  0.8518(TP)  0.8076(TP)  0.7925(TP)  0.7215(TP)  0.9454(TP)  0.9043(TP)\n",
      "4    0.6273(TP)  0.7414(TP)  0.7963(TP)  0.8518(TP)  0.0000(TP)  0.8280(TP)  0.6254(TP)  0.7670(TP)  0.8872(TP)  0.7666(TP)\n",
      "5    0.8732(TP)  0.8884(TP)  0.8490(TP)  0.8076(TP)  0.8280(TP)  0.0000(TP)  1.0181\u001b[93m(FN)\u001b[0m  0.9651(TP)  0.9104(TP)  0.8550(TP)\n",
      "6    0.6039(TP)  0.6791(TP)  0.7058(TP)  0.7925(TP)  0.6254(TP)  1.0181\u001b[93m(FN)\u001b[0m  0.0000(TP)  0.5409(TP)  0.8288(TP)  0.8342(TP)\n",
      "7    0.5684(TP)  0.6024(TP)  0.6925(TP)  0.7215(TP)  0.7670(TP)  0.9651(TP)  0.5409(TP)  0.0000(TP)  0.8965(TP)  0.8410(TP)\n",
      "8    0.8186(TP)  0.7650(TP)  0.7630(TP)  0.9454(TP)  0.8872(TP)  0.9104(TP)  0.8288(TP)  0.8965(TP)  0.0000(TP)  0.7252(TP)\n",
      "9    0.7623(TP)  0.6863(TP)  0.7677(TP)  0.9043(TP)  0.7666(TP)  0.8550(TP)  0.8342(TP)  0.8410(TP)  0.7252(TP)  0.0000(TP)\n"
     ]
    }
   ],
   "source": [
    "printDistance(emb_array, train_labels, end=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copying for save the original array\n",
    "emb_origin = np.empty_like(emb_array)\n",
    "np.copyto(emb_origin, emb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_pca, _ = PCAtransform(emb_array, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_pca, _ = PCAtransform(emb_origin, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0   1   photo_2016-11-04_19-33-44.png\n",
      "  1   1   photo_2016-11-19_23-42-00.png\n",
      "  2   1   photo_2016-12-25_20-59-04.png\n",
      "  3   1   photo_2016-12-25_20-59-23.png\n",
      "  4   1   photo_2017-03-10_12-46-19.png\n",
      "  5   1   photo_2017-05-23_21-38-22.png\n",
      "  6   1   photo_2017-08-26_20-24-22.png\n",
      "  7   1   photo_2017-09-08_15-05-01.png\n",
      "  8   1   photo_2017-10-24_15-01-13.png\n",
      "  9   1   photo_2017-10-31_16-36-11.png\n",
      "\n",
      " 10   3   photo_2016-07-04_22-38-35.png\n",
      " 11   3   photo_2016-07-12_13-26-07.png\n",
      " 12   3   photo_2016-07-21_00-38-16.png\n",
      " 13   3   photo_2016-12-12_17-25-22.png\n",
      " 14   3   photo_2017-01-14_20-14-58.png\n",
      " 15   3   photo_2017-05-19_00-35-56.png\n",
      " 16   3   photo_2017-07-15_17-05-07.png\n",
      " 17   3   photo_2017-07-23_23-45-38.png\n",
      " 18   3   photo_2017-09-18_12-12-13.png\n",
      " 19   3   photo_2017-09-26_00-32-31.png\n",
      " 20   3   photo_2017-11-17_01-42-09.png\n",
      " 21   3   photo_2017-11-17_01-42-51.png\n",
      " 22   3   photo_2017-11-17_01-43-40.png\n"
     ]
    }
   ],
   "source": [
    "printData(train_labels, train_paths, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cut false positives\n",
    "emb_del = np.empty_like(emb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 18 3 3 1.1004116607 FN\n",
      "10 20 3 3 1.0794165457 FN\n",
      "10 21 3 3 1.07996317147 FN\n",
      "10 22 3 3 1.08757811171 FN\n",
      "11 17 3 3 1.05254480804 FN\n",
      "12 18 3 3 1.0546051841 FN\n",
      "12 22 3 3 1.08865854368 FN\n",
      "13 21 3 3 1.08653335662 FN\n",
      "19 21 3 3 1.0742474607 FN\n"
     ]
    }
   ],
   "source": [
    "arr = emb_array\n",
    "\n",
    "lng = len(arr)\n",
    "summ = 0\n",
    "threshold = 1.05\n",
    "\n",
    "for i in range(lng):\n",
    "    for j in range(i, lng):\n",
    "        dist = np.linalg.norm(arr[i,:] - arr[j,:])\n",
    "        if (train_labels[i] == train_labels[j]) and (dist > threshold):\n",
    "            print(i,j,train_labels[i],train_labels[j], dist, \"FN\")\n",
    "        elif (train_labels[i] != train_labels[j]) and (dist <= threshold):\n",
    "            print(i,j,train_labels[i],train_labels[j], dist, \"FP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_del = np.delete(emb_array, (10, 11, 13, 19, 22), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c, w = trainFisherWithNum(emb_del, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -4.16333634234e-17\n",
      "1 -9.02056207508e-17\n",
      "2 -1.07552855511e-16\n",
      "3 -1.2490009027e-16\n",
      "4 -6.93889390391e-17\n",
      "5 -1.17961196366e-16\n",
      "6 -2.77555756156e-17\n",
      "7 -5.55111512313e-17\n",
      "8 -6.93889390391e-17\n",
      "9 -9.71445146547e-17\n",
      "10 0.0624907122675\n",
      "11 0.105591563776\n",
      "12 0.0\n",
      "13 -0.0117851814857\n",
      "14 -7.2858385991e-17\n",
      "15 -3.81639164715e-17\n",
      "16 -7.6327832943e-17\n",
      "17 -9.71445146547e-17\n",
      "18 -2.77555756156e-17\n",
      "19 -0.0104855840395\n",
      "20 -3.46944695195e-17\n",
      "21 -1.38777878078e-17\n",
      "22 -0.0581120860376\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(emb_array)):\n",
    "    l = Fisher(w, c, emb_array[i])\n",
    "    print(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
